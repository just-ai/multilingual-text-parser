# Обучение теггера

Запустить скрипт `train_tagger.py`.

Обязательные аргументы:

--label_list список классов

--train_dataset путь к трейн датасету

--dev_dataset путь к валидационному датасету

--test_dataset путь к тестовому датасету

Необязательные аргументы:

--train для обучения с нуля, --no-train для файнтюнинга. По дефолту стоит `True`

--model_name имя предобученной модели из transformers. По дефолту "sberbank-ai/ruBert-large", но мы использовали "cointegrated/rubert-tiny2"

--pretrained_model если стоит режим файнтюнинга, то нужен путь к предобученной модели. Выбросит ошибку, если не указать

--tagger_name путь, куда сохранить модель. По дефолту "tagger"

--num_epoch по дефолту 5

--lr по дефолту 3e-5

--weight_decay по дефолту 0.1

--warmup_ratio по дефолту 0.06

--cache_dir_tokenizer папка, куда кэшируется токенайзер

--cache_dir_model папка, куда кэшируется модель

# Сборка датасета

Датасет собирается из двух других датасетов:
[NEREL](https://github.com/nerel-ds/nerel) и [Google](https://www.kaggle.com/competitions/text-normalization-challenge-russian-language/data).
Из первого берутся семплы для дат и римских цифр, из второго -- для времени, дробей, порядковых и количественных числительных.
Сборка каждого датасета производится в отдельных скриптах: `get_ds_nerel.py` и `get_ds_google.py` соответственно.
Если надо добавить какой-то новый класс или поправить один из имеющихся, то это можно сделать в одном из этих скриптов.
Сборка производится по следующему пайплайну:
1. Собирается датасет на основе NEREL
2. На этом датасете обучается модель предсказывать даты и римские цифры
3. Собирается датасет на основе Google, но для этого нужна модель обученная на даты, чтобы поправлять неверные семплы
4. Обучается вторая модель предсказывать числительные и время
5. Обе модели предсказывают классы в тех датасетах, в которых их нет (модель, обученная на гугловском датасете размечает датасет нерел, и наоборот)
6. Сохраняется общий датасет

Запустить скрипт `build_ds.py`. Запускать можно частями, просто указав нужные аргументы. Все аргументы не обязательные, по дефолту уже стоят какие-то имена для датасетов и моделей.

Nerel:

--build_nerel надо собирать датасет нерел или нет. По дефолту `True`

--parent_dir_nerel папка с датасетом. По дефолту "NEREL/NEREL-v1.0/"

--train_filename_nerel имя файла с обучающим датасетом (без расширения)

--dev_filename_nerel имя файла с валидационным датасетом

--test_filename_nerel имя файла с тестовым датасетом

--model_nerel путь к модели, обучающейся на датасете нерел (либо куда ее сохранить, если в ходе пайплайна она обучается, либо где лежит уже обученная модель)

--nerel_pretrained обучена модель на этом датасете или нет

Google (суть та же):

--build_google

--train_filename_google

--dev_filename_google

--test_filename_google

--data_google путь к файлу с датасетом. По дефолту "ru_train.csv"

--model_google

--google_pretrained

Весь датасет:

--train_filename

--dev_filename

--test_filename
